# work_recommendation_system
## 0. 需求
- 需求，是爬取各招聘网站。所以我去爬了，首先得确定一个网站去爬嘛，首选拉钩网，谁让它的卖像好呢。所以我抄起家伙就开始爬了。可惜卖像最好的家伙，没想到它的拌猪吃老虎，它的反爬虫历害的一批，各种限制，算了，怂了怂了。就另谋它法，退而求其次。  
- 网站的选择呢，首先它得有一定的数据量。其次，保证我需要的数据信息它都有（我需要什么信息呢，后面会有提到）。在就是它的网站的设计，至少得有模有样。所以我选择了50job前程无优。  
- 刚开始爬了，单线程导致数据贼慢，慢就不说了，由于用python做了一些数据预处理，导致数据极为不规整。直接导致，我后期使用的mapreduce增加的非常大的难度。所以这次爬了1晚几百兆的数据作废，不过可以做了测试数据进行后面的业务分析。  
- 数据还得在爬嘛，不过在按之前的方案，百万数据遥遥无期。这时，为了爬虫的性能，这时，多进程，协程就出现了。这次认为我的数据应该没有问题了。不曾想还是会有一些问题。  
- 所以开始的爬虫3.0。这次没啥大问题。

## 1. spider_code
- 主要是一些爬虫代码， 指标分析需要相当的数据量， 所以需要一些测试数据，本系统数据来源是51Job。

## 2. 数据清洗
- 尽量保证数据完整、一致性的条件下，做数据清洗。
- 去掉重复的数据。
- 将一些String字段，转换成int类型的字段，方便后期做数据分析。

### 数据字段
1. job_title string 职业标题
2. work_city string 工作城市
3. work_experience int 工作经验
4. education string 教育经历
5. company_demand string 招人要求
6. other_asks string 公司其他要求
7. company_name string 公司名称
8. salary float 工资
9. position string 职能
10. company_type string 公司类型
11. company_size string 公司规模
12. address string 公司地址
13. job_message string 工作简介

## 3. 指标分析
统计指标  
1. 涨幅(薪水)  
	a. 例：大数据这个行业，在每一天的各个城市的涨幅。
	b. 例：在同一个时候， 各大行业的各个城市的涨幅情况。
2. 热门(个数)：  
	a. 例：全国各大城市，最受欢迎的职位。我取的前10
	b. 例：大数据这个行业，在全国各个城市，热度(职业个数)。
3. 行业():  
	a. 例：全国各大城市，各个职位，薪水最高的前10个职业
	b. 例：工作经验在1到3年全国或者同城市top10职业
